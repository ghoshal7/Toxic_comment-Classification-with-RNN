{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73764f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re, string\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option('display.max_rows', 20)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7787d6f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on improvement - I wondered if the section statistics should be later on, or a subsection of \"\"types of accidents\"\"  -I think the references may need tidying so that they are all in the exact same format ie date format etc. I can do that later on, if no-one else does first - if you have any preferences for formatting style on references or want to do it yourself please let me know.\\n\\nThere appears to be a backlog on articles for review so I guess there may be a delay until a reviewer turns up. It's listed in the relevant form eg Wikipedia:Good_article_nominations#Transport  \"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember what page that's on?</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  \\\n",
       "0  0000997932d777bf   \n",
       "1  000103f0d9cfb60f   \n",
       "2  000113f07ec002fd   \n",
       "3  0001b41b1c6bb37e   \n",
       "4  0001d958c54c6e35   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         comment_text  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                           Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                           Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on improvement - I wondered if the section statistics should be later on, or a subsection of \"\"types of accidents\"\"  -I think the references may need tidying so that they are all in the exact same format ie date format etc. I can do that later on, if no-one else does first - if you have any preferences for formatting style on references or want to do it yourself please let me know.\\n\\nThere appears to be a backlog on articles for review so I guess there may be a delay until a reviewer turns up. It's listed in the relevant form eg Wikipedia:Good_article_nominations#Transport  \"   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 You, sir, are my hero. Any chance you remember what page that's on?   \n",
       "\n",
       "   toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0      0             0        0       0       0              0  \n",
       "1      0             0        0       0       0              0  \n",
       "2      0             0        0       0       0              0  \n",
       "3      0             0        0       0       0              0  \n",
       "4      0             0        0       0       0              0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '/Users/my_MAC/Coding/data/jigsaw-toxic-comment-classification-challenge/'\n",
    "df = pd.read_csv(path+'train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d52b3eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\n",
    "\n",
    "import nltk\n",
    "from nltk import sent_tokenize,word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from tqdm import tqdm\n",
    "from nltk.stem.porter import *\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import gensim\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c5a0694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27</td>\n",
       "      <td>explanation edits made username hardcore metallica fan reverted werent vandalism closure gas voted new york doll fac please dont remove template talk page since im retired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)</td>\n",
       "      <td>daww match background colour im seemingly stuck thanks talk january utc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.</td>\n",
       "      <td>hey man im really trying edit war guy constantly removing relevant information talking edits instead talk page seems care formatting actual info</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on improvement - I wondered if the section statistics should be later on, or a subsection of \"\"types of accidents\"\"  -I think the references may need tidying so that they are all in the exact same format ie date format etc. I can do that later on, if no-one else does first - if you have any preferences for formatting style on references or want to do it yourself please let me know.\\n\\nThere appears to be a backlog on articles for review so I guess there may be a delay until a reviewer turns up. It's listed in the relevant form eg Wikipedia:Good_article_nominations#Transport  \"</td>\n",
       "      <td>cant make real suggestion improvement wondered section statistic later subsection type accident think reference may need tidying exact format ie date format etc later noone else first preference formatting style reference want please let know appears backlog article review guess may delay reviewer turn listed relevant form eg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember what page that's on?</td>\n",
       "      <td>sir hero chance remember page thats</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         comment_text  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                           Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                           Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on improvement - I wondered if the section statistics should be later on, or a subsection of \"\"types of accidents\"\"  -I think the references may need tidying so that they are all in the exact same format ie date format etc. I can do that later on, if no-one else does first - if you have any preferences for formatting style on references or want to do it yourself please let me know.\\n\\nThere appears to be a backlog on articles for review so I guess there may be a delay until a reviewer turns up. It's listed in the relevant form eg Wikipedia:Good_article_nominations#Transport  \"   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 You, sir, are my hero. Any chance you remember what page that's on?   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                clean_text  \n",
       "0                                                                                                                                                              explanation edits made username hardcore metallica fan reverted werent vandalism closure gas voted new york doll fac please dont remove template talk page since im retired  \n",
       "1                                                                                                                                                                                                                                                                  daww match background colour im seemingly stuck thanks talk january utc  \n",
       "2                                                                                                                                                                                         hey man im really trying edit war guy constantly removing relevant information talking edits instead talk page seems care formatting actual info  \n",
       "3  cant make real suggestion improvement wondered section statistic later subsection type accident think reference may need tidying exact format ie date format etc later noone else first preference formatting style reference want please let know appears backlog article review guess may delay reviewer turn listed relevant form eg  \n",
       "4                                                                                                                                                                                                                                                                                                      sir hero chance remember page thats  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pre_preprocess_text(text, stemming=False, lemmatizing=True, sw=None, punct_list = None):\n",
    "    ## clean (convert to lowercase and remove punctuations and characters and then strip)\n",
    "    text = re.sub(r'[^\\w\\s]', '', str(text).lower().strip())\n",
    "            \n",
    "    ## Tokenize (convert from string to list)\n",
    "    text_token = text.split()\n",
    "    ## remove Stopwords\n",
    "    if sw is not None:\n",
    "        text_stopwordFree = [word for word in text_token if word not in sw]\n",
    "        \n",
    "    # Checking all words is alphabets or not - if not remove\n",
    "    text_alphabets = [i for i in text_stopwordFree if i.isalpha()]\n",
    "    \n",
    "    # punctuations free\n",
    "    if punct_list is not None:\n",
    "        text_punctFree = [w for w in text_alphabets if w not in punct_list]\n",
    "                \n",
    "    ## Stemming (remove -ing, -ly, ...)\n",
    "    if stemming == True:\n",
    "        ps = nltk.stem.porter.PorterStemmer()\n",
    "        text_clean = [ps.stem(word) for word in text_punctFree]\n",
    "                \n",
    "    ## Lemmatisation (convert the word into root word)\n",
    "    if lemmatizing == True:\n",
    "        lem = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "        text_clean = [lem.lemmatize(word) for word in text_punctFree]\n",
    "            \n",
    "    ## back to string from list\n",
    "    text = \" \".join(text_clean)\n",
    "    \n",
    "    return text\n",
    "\n",
    "stopwords_list = nltk.corpus.stopwords.words(\"english\")\n",
    "puncts = [i for i in string.punctuation]\n",
    "\n",
    "df['clean_text'] = df['comment_text'].apply(lambda x: pre_preprocess_text(x, sw=stopwords_list, \n",
    "                                                                            punct_list = puncts))\n",
    "\n",
    "df[['comment_text','clean_text']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe9d5c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfv = TfidfVectorizer(max_features=1000, strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\n",
    "                      ngram_range=(1, 1), use_idf=1,smooth_idf=1,sublinear_tf=1, stop_words = 'english')\n",
    "\n",
    "x = tfv.fit_transform(df['clean_text'])\n",
    "all_labels = ['toxic','severe_toxic','obscene','threat','insult','identity_hate']\n",
    "y = df[all_labels]\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x,y, random_state=43, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d985a99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "\n",
    "import warnings\n",
    "# warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce93cabb",
   "metadata": {},
   "source": [
    "## A. Simple Problem Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2786f969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scikit-multilearn\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from skmultilearn.problem_transform import LabelPowerset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7161ae1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "692afc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def mlc_LP(base_clf):\n",
    "    strt = time.time()\n",
    "    clf = LabelPowerset(classifier=base_clf)\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_hat = clf.predict(x_valid)\n",
    "    hamming_loss = metrics.hamming_loss(y_valid, y_hat)\n",
    "    accuracy = metrics.accuracy_score(y_valid, y_hat)\n",
    "    time_taken = time.time() - strt\n",
    "    print(\"hamming loss = \", hamming_loss, \"accuracy = \", accuracy, \"time taken = \", time_taken)\n",
    "    return hamming_loss, accuracy, time_taken\n",
    "\n",
    "def mlc_BR(base_clf):\n",
    "    strt = time.time()\n",
    "    clf = BinaryRelevance(classifier=base_clf)\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_hat = clf.predict(x_valid)\n",
    "    hamming_loss = metrics.hamming_loss(y_valid, y_hat)\n",
    "    accuracy = metrics.accuracy_score(y_valid, y_hat)\n",
    "    time_taken = time.time() - strt\n",
    "    print(\"hamming loss = \", hamming_loss, \"accuracy = \", accuracy, \"time taken = \", time_taken)\n",
    "    return hamming_loss, accuracy, time_taken\n",
    "\n",
    "def mlc_CC(base_clf):\n",
    "    strt = time.time()\n",
    "    clf = ClassifierChain(classifier=base_clf)\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_hat = clf.predict(x_valid)\n",
    "    hamming_loss = metrics.hamming_loss(y_valid, y_hat)\n",
    "    accuracy = metrics.accuracy_score(y_valid, y_hat)\n",
    "    time_taken = time.time() - strt\n",
    "    print(\"hamming loss = \", hamming_loss, \"accuracy = \", accuracy, \"time taken = \", time_taken)\n",
    "    return hamming_loss, accuracy, time_taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "095cc814",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hamming loss =  0.021144707295420128 accuracy =  0.9160269465768447 time taken =  38.135905027389526\n",
      "MultinomialNB\n",
      "hamming loss =  0.024842028304350096 accuracy =  0.9106689644367852 time taken =  1.894563913345337\n",
      "LinearSVC\n",
      "hamming loss =  0.021515483837276098 accuracy =  0.9157449475168417 time taken =  10.236384868621826\n",
      "LogisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hamming loss =  0.020371820982818947 accuracy =  0.917248942503525 time taken =  33.25800704956055\n",
      "MultinomialNB\n",
      "hamming loss =  0.031845004961094575 accuracy =  0.8988563371455428 time taken =  3.4958109855651855\n",
      "LinearSVC\n",
      "hamming loss =  0.02063815342837746 accuracy =  0.9167476108412972 time taken =  12.775354146957397\n",
      "LogisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hamming loss =  0.02028304350096611 accuracy =  0.9168102772990757 time taken =  23.507508993148804\n",
      "MultinomialNB\n",
      "hamming loss =  0.022580813619510157 accuracy =  0.9129562901456996 time taken =  3.3632960319519043\n",
      "LinearSVC\n",
      "hamming loss =  0.020298710115410727 accuracy =  0.9169042769857434 time taken =  236.77040886878967\n"
     ]
    }
   ],
   "source": [
    "CLFs = [LogisticRegression(random_state=43), MultinomialNB(), LinearSVC()]\n",
    "\n",
    "entries = []\n",
    "for i in CLFs:\n",
    "    base_clf = str(i.__class__.__name__)\n",
    "    print(base_clf)\n",
    "    a,b,c = mlc_LP(i)\n",
    "    entries.append((base_clf,a,b,c))\n",
    "        \n",
    "results_LP = pd.DataFrame(entries, columns=['Base_classifier', 'Hamming_loss', 'Accuracy', 'Time_taken'])\n",
    "results_LP['MLC'] = \"LP\"\n",
    "\n",
    "\n",
    "entries = []\n",
    "for i in CLFs:\n",
    "    base_clf = str(i.__class__.__name__)\n",
    "    print(base_clf)\n",
    "    a,b,c = mlc_CC(i)\n",
    "    entries.append((base_clf,a,b,c))\n",
    "        \n",
    "results_CC = pd.DataFrame(entries, columns=['Base_classifier', 'Hamming_loss', 'Accuracy', 'Time_taken'])\n",
    "results_CC['MLC'] = \"CC\"\n",
    "\n",
    "\n",
    "\n",
    "entries = []\n",
    "for i in CLFs:\n",
    "    base_clf = str(i.__class__.__name__)\n",
    "    print(base_clf)\n",
    "    a,b,c = mlc_BR(i)\n",
    "    entries.append((base_clf,a,b,c))\n",
    "        \n",
    "results_BR = pd.DataFrame(entries, columns=['Base_classifier', 'Hamming_loss', 'Accuracy', 'Time_taken'])\n",
    "results_BR['MLC'] = \"BR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02754238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Base_classifier</th>\n",
       "      <th>Hamming_loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Time_taken</th>\n",
       "      <th>MLC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.021145</td>\n",
       "      <td>0.916027</td>\n",
       "      <td>38.135905</td>\n",
       "      <td>LP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.024842</td>\n",
       "      <td>0.910669</td>\n",
       "      <td>1.894564</td>\n",
       "      <td>LP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.021515</td>\n",
       "      <td>0.915745</td>\n",
       "      <td>10.236385</td>\n",
       "      <td>LP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.020283</td>\n",
       "      <td>0.916810</td>\n",
       "      <td>23.507509</td>\n",
       "      <td>BR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.022581</td>\n",
       "      <td>0.912956</td>\n",
       "      <td>3.363296</td>\n",
       "      <td>BR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.020299</td>\n",
       "      <td>0.916904</td>\n",
       "      <td>236.770409</td>\n",
       "      <td>BR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.020372</td>\n",
       "      <td>0.917249</td>\n",
       "      <td>33.258007</td>\n",
       "      <td>CC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.031845</td>\n",
       "      <td>0.898856</td>\n",
       "      <td>3.495811</td>\n",
       "      <td>CC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.020638</td>\n",
       "      <td>0.916748</td>\n",
       "      <td>12.775354</td>\n",
       "      <td>CC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Base_classifier  Hamming_loss  Accuracy  Time_taken MLC\n",
       "0  LogisticRegression      0.021145  0.916027   38.135905  LP\n",
       "1       MultinomialNB      0.024842  0.910669    1.894564  LP\n",
       "2           LinearSVC      0.021515  0.915745   10.236385  LP\n",
       "0  LogisticRegression      0.020283  0.916810   23.507509  BR\n",
       "1       MultinomialNB      0.022581  0.912956    3.363296  BR\n",
       "2           LinearSVC      0.020299  0.916904  236.770409  BR\n",
       "0  LogisticRegression      0.020372  0.917249   33.258007  CC\n",
       "1       MultinomialNB      0.031845  0.898856    3.495811  CC\n",
       "2           LinearSVC      0.020638  0.916748   12.775354  CC"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.concat([results_LP, results_BR, results_CC])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f1d3309",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MLC</th>\n",
       "      <th>Hamming_loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Time_taken</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BR</td>\n",
       "      <td>0.021054</td>\n",
       "      <td>0.915557</td>\n",
       "      <td>87.880405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CC</td>\n",
       "      <td>0.024285</td>\n",
       "      <td>0.910951</td>\n",
       "      <td>16.509724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LP</td>\n",
       "      <td>0.022501</td>\n",
       "      <td>0.914147</td>\n",
       "      <td>16.755618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  MLC  Hamming_loss  Accuracy  Time_taken\n",
       "0  BR      0.021054  0.915557   87.880405\n",
       "1  CC      0.024285  0.910951   16.509724\n",
       "2  LP      0.022501  0.914147   16.755618"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.groupby('MLC').mean().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd571f78",
   "metadata": {},
   "source": [
    "## B. Algorithm Adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f25eb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmultilearn.adapt import MLkNN\n",
    "from skmultilearn.adapt import BRkNNaClassifier\n",
    "from skmultilearn.adapt import MLTSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "106e8a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass n_neighbors=2 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hamming loss =  0.04026842132748446 accuracy =  0.8519191602694658 time taken =  811.156965970993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass n_neighbors=2 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hamming loss =  0.027395686458822916 accuracy =  0.9018643271189096 time taken =  115.82356405258179\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adapt_algo</th>\n",
       "      <th>Hamming_loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Time_taken</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLkNN</td>\n",
       "      <td>0.040268</td>\n",
       "      <td>0.851919</td>\n",
       "      <td>811.156966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BRkNNaClassifier</td>\n",
       "      <td>0.027396</td>\n",
       "      <td>0.901864</td>\n",
       "      <td>115.823564</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Adapt_algo  Hamming_loss  Accuracy  Time_taken\n",
       "0             MLkNN      0.040268  0.851919  811.156966\n",
       "1  BRkNNaClassifier      0.027396  0.901864  115.823564"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adapt_clf = [MLkNN(k=2), BRkNNaClassifier(k=2)]\n",
    "\n",
    "entries = []\n",
    "for clf in adapt_clf:\n",
    "    strt = time.time()\n",
    "#     clf.fit(np.array(x_train), np.array(y_train))\n",
    "    clf.fit(x_train.toarray(), np.array(y_train))\n",
    "    y_hat = clf.predict(x_valid)\n",
    "    hamming_loss = metrics.hamming_loss(y_valid, y_hat)\n",
    "    accuracy = metrics.accuracy_score(y_valid, y_hat)\n",
    "    time_taken = time.time() - strt\n",
    "    print(\"hamming loss = \", hamming_loss, \"accuracy = \", accuracy, \"time taken = \", time_taken)\n",
    "    entries.append((str(clf.__class__.__name__), hamming_loss, accuracy, time_taken))\n",
    "    \n",
    "results_adaptalgo = pd.DataFrame(entries, columns=['MLC', 'Hamming_loss', 'Accuracy', 'Time_taken'])\n",
    "\n",
    "results_adaptalgo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92ad7603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MLC</th>\n",
       "      <th>Hamming_loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Time_taken</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLkNN</td>\n",
       "      <td>0.040268</td>\n",
       "      <td>0.851919</td>\n",
       "      <td>811.156966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BRkNNaClassifier</td>\n",
       "      <td>0.027396</td>\n",
       "      <td>0.901864</td>\n",
       "      <td>115.823564</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                MLC  Hamming_loss  Accuracy  Time_taken\n",
       "0             MLkNN      0.040268  0.851919  811.156966\n",
       "1  BRkNNaClassifier      0.027396  0.901864  115.823564"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_adaptalgo = pd.DataFrame(entries, columns=['MLC', 'Hamming_loss', 'Accuracy', 'Time_taken'])\n",
    "\n",
    "results_adaptalgo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97861cba",
   "metadata": {},
   "source": [
    "## C. Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3eca62b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hamming loss =  0.020789597368008773 accuracy =  0.9154629484568385 time taken =  30.27391791343689\n",
      "MultinomialNB\n",
      "hamming loss =  0.023714032064337563 accuracy =  0.9104182986056714 time taken =  3.6457748413085938\n",
      "LinearSVC\n",
      "hamming loss =  0.021071596428011905 accuracy =  0.9160896130346232 time taken =  8.934327125549316\n"
     ]
    }
   ],
   "source": [
    "from skmultilearn.ensemble import RakelD\n",
    "\n",
    "def ensemble_rakel(base_clf):\n",
    "    strt = time.time()\n",
    "    clf = RakelD(base_classifier=base_clf)\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_hat = clf.predict(x_valid)\n",
    "    hamming_loss = metrics.hamming_loss(y_valid, y_hat)\n",
    "    accuracy = metrics.accuracy_score(y_valid, y_hat)\n",
    "    time_taken = time.time() - strt\n",
    "    print(\"hamming loss = \", hamming_loss, \"accuracy = \", accuracy, \"time taken = \", time_taken)\n",
    "    return hamming_loss, accuracy, time_taken\n",
    "\n",
    "entries = []\n",
    "for i in CLFs:\n",
    "    base_clf = str(i.__class__.__name__)\n",
    "    print(base_clf)\n",
    "    a,b,c = ensemble_rakel(i)\n",
    "    entries.append((base_clf,a,b,c))\n",
    "        \n",
    "results_rakel = pd.DataFrame(entries, columns=['Base_classifier', 'Hamming_loss', 'Accuracy', 'Time_taken'])\n",
    "results_rakel['MLC'] = \"Ensemble\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62740a5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Base_classifier</th>\n",
       "      <th>Hamming_loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Time_taken</th>\n",
       "      <th>MLC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.020790</td>\n",
       "      <td>0.915463</td>\n",
       "      <td>30.273918</td>\n",
       "      <td>Ensemble</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.023714</td>\n",
       "      <td>0.910418</td>\n",
       "      <td>3.645775</td>\n",
       "      <td>Ensemble</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.021072</td>\n",
       "      <td>0.916090</td>\n",
       "      <td>8.934327</td>\n",
       "      <td>Ensemble</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Base_classifier  Hamming_loss  Accuracy  Time_taken       MLC\n",
       "0  LogisticRegression      0.020790  0.915463   30.273918  Ensemble\n",
       "1       MultinomialNB      0.023714  0.910418    3.645775  Ensemble\n",
       "2           LinearSVC      0.021072  0.916090    8.934327  Ensemble"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_rakel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df2bee2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Base_classifier</th>\n",
       "      <th>Hamming_loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Time_taken</th>\n",
       "      <th>MLC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.021145</td>\n",
       "      <td>0.916027</td>\n",
       "      <td>38.135905</td>\n",
       "      <td>LP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.024842</td>\n",
       "      <td>0.910669</td>\n",
       "      <td>1.894564</td>\n",
       "      <td>LP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.021515</td>\n",
       "      <td>0.915745</td>\n",
       "      <td>10.236385</td>\n",
       "      <td>LP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.020283</td>\n",
       "      <td>0.916810</td>\n",
       "      <td>23.507509</td>\n",
       "      <td>BR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.022581</td>\n",
       "      <td>0.912956</td>\n",
       "      <td>3.363296</td>\n",
       "      <td>BR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.020299</td>\n",
       "      <td>0.916904</td>\n",
       "      <td>236.770409</td>\n",
       "      <td>BR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.020372</td>\n",
       "      <td>0.917249</td>\n",
       "      <td>33.258007</td>\n",
       "      <td>CC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.031845</td>\n",
       "      <td>0.898856</td>\n",
       "      <td>3.495811</td>\n",
       "      <td>CC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.020638</td>\n",
       "      <td>0.916748</td>\n",
       "      <td>12.775354</td>\n",
       "      <td>CC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.040268</td>\n",
       "      <td>0.851919</td>\n",
       "      <td>811.156966</td>\n",
       "      <td>MLkNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.027396</td>\n",
       "      <td>0.901864</td>\n",
       "      <td>115.823564</td>\n",
       "      <td>BRkNNaClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.020790</td>\n",
       "      <td>0.915463</td>\n",
       "      <td>30.273918</td>\n",
       "      <td>Ensemble</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.023714</td>\n",
       "      <td>0.910418</td>\n",
       "      <td>3.645775</td>\n",
       "      <td>Ensemble</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.021072</td>\n",
       "      <td>0.916090</td>\n",
       "      <td>8.934327</td>\n",
       "      <td>Ensemble</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Base_classifier  Hamming_loss  Accuracy  Time_taken               MLC\n",
       "0  LogisticRegression      0.021145  0.916027   38.135905                LP\n",
       "1       MultinomialNB      0.024842  0.910669    1.894564                LP\n",
       "2           LinearSVC      0.021515  0.915745   10.236385                LP\n",
       "0  LogisticRegression      0.020283  0.916810   23.507509                BR\n",
       "1       MultinomialNB      0.022581  0.912956    3.363296                BR\n",
       "2           LinearSVC      0.020299  0.916904  236.770409                BR\n",
       "0  LogisticRegression      0.020372  0.917249   33.258007                CC\n",
       "1       MultinomialNB      0.031845  0.898856    3.495811                CC\n",
       "2           LinearSVC      0.020638  0.916748   12.775354                CC\n",
       "0                 NaN      0.040268  0.851919  811.156966             MLkNN\n",
       "1                 NaN      0.027396  0.901864  115.823564  BRkNNaClassifier\n",
       "0  LogisticRegression      0.020790  0.915463   30.273918          Ensemble\n",
       "1       MultinomialNB      0.023714  0.910418    3.645775          Ensemble\n",
       "2           LinearSVC      0.021072  0.916090    8.934327          Ensemble"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([results,results_adaptalgo,results_rakel])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b12664c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
